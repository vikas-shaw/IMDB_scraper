{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import time\n",
    "import random as ran\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.imdb.com/search/title?release_date=2018&sort=boxoffice_gross_us,desc&start=1'\n",
    "\n",
    "url_response = requests.get(url).text\n",
    "parser_html = bs4.BeautifulSoup(url_response,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_blocks = parser_html.findAll('div',{'class':'lister-item-content'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_name = movie_blocks[0].find('a').get_text() \n",
    "\n",
    "movie_rating = float(movie_blocks[0].find('div',{'class':'inline-block ratings-imdb-rating'}).get('data-value'))\n",
    "\n",
    "movie_year = int(movie_blocks[0].find('span',{'class': 'lister-item-year'}).contents[0][1:-1]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_mblock(movie_block):\n",
    "    \n",
    "    movie_data ={}\n",
    "  \n",
    "    movie_data['name'] = movie_block.find('a').get_text() \n",
    "\n",
    "    movie_data['rating'] = float(movie_block.find('div',{'class':'inline-block ratings-imdb-rating'}).get('data-value')) \n",
    "\n",
    "    movie_data['year'] = str(movie_block.find('span',{'class': 'lister-item-year'}).contents[0][1:-1])\n",
    "    \n",
    "    return movie_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_movie_page(movie_blocks):\n",
    "    \n",
    "    page_movie_data = []\n",
    "    num_blocks = len(movie_blocks)\n",
    "    \n",
    "    for block in range(num_blocks):\n",
    "        page_movie_data.append(scrap_mblock(movie_blocks[block]))\n",
    "    \n",
    "    return page_movie_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_web(link,t_count):\n",
    "\n",
    "    base_url = link\n",
    "    target = t_count\n",
    "    \n",
    "    current_mcount_start = 0\n",
    "    current_mcount_end = 0\n",
    "    remaining_mcount = target - current_mcount_end \n",
    "    \n",
    "    new_page_number = 1\n",
    "    \n",
    "    movie_data = []\n",
    "    \n",
    "    \n",
    "    while remaining_mcount > 0:\n",
    "\n",
    "        url = base_url + str(new_page_number)\n",
    "        \n",
    "        source = requests.get(url).text\n",
    "        soup = bs4.BeautifulSoup(source,'html.parser')\n",
    "        \n",
    "        movie_blocks = soup.findAll('div',{'class':'lister-item-content'})\n",
    "        \n",
    "        movie_data.extend(scrap_movie_page(movie_blocks))   \n",
    "        \n",
    "        current_mcount_start = int(soup.find(\"div\", {\"class\":\"nav\"}).find(\"div\", {\"class\": \"desc\"}).contents[1].get_text().split(\"-\")[0])\n",
    "\n",
    "        remaining_mcount = target - current_mcount_end\n",
    "        \n",
    "        print('\\r' + \"currently scraping movies from page : \" + str(current_mcount_start) , end =\"\")\n",
    "        new_page_number = current_mcount_start + 1\n",
    "        \n",
    "        time.sleep(ran.randint(0, 10))\n",
    "    \n",
    "    return movie_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currently scraping movies from page : 13"
     ]
    }
   ],
   "source": [
    "base_scraping_link = \"https://www.imdb.com/search/title?release_date=2018-01-01,2018-12-31&sort=boxoffice_gross_us,desc&start=\"\n",
    "\n",
    "top_movies = 1000 \n",
    "films = []\n",
    "\n",
    "films = scrap_web(base_scraping_link,int(top_movies))\n",
    "\n",
    "print('\\r'+\"List of top \" + str(top_movies) +\" movies:\" + \"\\n\", end=\"\\n\")\n",
    "pd.DataFrame(films)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_csv = pd.DataFrame(films)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_movies = pd.DataFrame(dataframe_csv)\n",
    "filename = 'imdb_movies.csv'\n",
    "imdb_movies.to_csv(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
